<?xml version="1.0"?>
<launch>
  <!-- Parameter files -->
  <arg name="object_recognition_detection_object_lanelet_filter_param_path"/>
  <arg name="object_recognition_detection_object_position_filter_param_path"/>
  <arg name="object_recognition_detection_pointcloud_map_filter_param_path"/>
  <arg name="object_recognition_tracking_multi_object_tracker_data_association_matrix_param_path"/>
  <arg name="obstacle_segmentation_ground_segmentation_param_path"/>
  <arg name="obstacle_segmentation_ground_segmentation_elevation_map_param_path"/>

  <!-- centerpoint model configs -->
  <arg name="centerpoint_model_name" default="centerpoint_tiny" description="options: `centerpoint` or `centerpoint_tiny`"/>
  <arg name="centerpoint_model_path" default="$(find-pkg-share lidar_centerpoint)/data"/>
  <arg name="centerpoint_model_param_path" default="$(find-pkg-share lidar_centerpoint)/config/$(var centerpoint_model_name).param.yaml"/>

  <!-- common parameters -->
  <arg name="input/pointcloud" default="/sensing/lidar/concatenated/pointcloud" description="The topic will be used in the detection module"/>
  <arg name="mode" default="lidar" description="options: `camera_lidar_radar_fusion`, `camera_lidar_fusion`, `lidar_radar_fusion`, `lidar` or `radar`"/>
  <arg name="lidar_detection_model" default="centerpoint" description="options: `centerpoint`, `apollo`, `pointpainting`, `clustering`"/>
  <arg name="image_raw0" default="/sensing/camera/camera0/image_rect_color" description="image raw topic name"/>
  <arg name="camera_info0" default="/sensing/camera/camera0/camera_info" description="camera info topic name"/>
  <arg name="image_raw1" default="/sensing/camera/camera1/image_rect_color"/>
  <arg name="camera_info1" default="/sensing/camera/camera1/camera_info"/>
  <arg name="image_raw2" default="/sensing/camera/camera2/image_rect_color"/>
  <arg name="camera_info2" default="/sensing/camera/camera2/camera_info"/>
  <arg name="image_raw3" default="/sensing/camera/camera3/image_rect_color"/>
  <arg name="camera_info3" default="/sensing/camera/camera3/camera_info"/>
  <arg name="image_raw4" default="/sensing/camera/camera4/image_rect_color"/>
  <arg name="camera_info4" default="/sensing/camera/camera4/camera_info"/>
  <arg name="image_raw5" default="/sensing/camera/camera5/image_rect_color"/>
  <arg name="camera_info5" default="/sensing/camera/camera5/camera_info"/>
  <arg name="image_raw6" default="/sensing/camera/camera6/image_rect_color"/>
  <arg name="camera_info6" default="/sensing/camera/camera6/camera_info"/>
  <arg name="image_raw7" default="/sensing/camera/camera7/image_rect_color"/>
  <arg name="camera_info7" default="/sensing/camera/camera7/camera_info"/>
  <arg name="image_number" default="6" description="choose image raw number(0-7)"/>
  <arg name="use_vector_map" default="false" description="use vector map in prediction"/>
  <arg name="use_pointcloud_map" default="false" description="use pointcloud map in detection"/>
  <arg name="use_object_filter" default="false" description="use object filter"/>
  <arg
    name="use_empty_dynamic_object_publisher"
    default="false"
    description="if use_empty_dynamic_object_publisher:=true, /perception/object_recognition/objects topic has an empty DynamicObjectArray"
  />
  <arg name="use_pointcloud_container" default="false" description="launch pointcloud container"/>
  <arg name="pointcloud_container_name" default="pointcloud_container"/>
  <!-- Traffic Light Recognition Parameters -->
  <arg name="use_traffic_light_recognition" default="false"/>
  <arg name="traffic_light_recognition/enable_fine_detection" default="false"/>

  <!-- perception module -->
  <group>
    <push-ros-namespace namespace="perception"/>

    <!-- object segmentation module -->
    <group>
      <push-ros-namespace namespace="obstacle_segmentation"/>
      <include file="$(find-pkg-share tier4_perception_launch)/launch/obstacle_segmentation/ground_segmentation/ground_segmentation.launch.py">
        <arg name="base_frame" value="base_link"/>
        <arg name="use_intra_process" value="true"/>
        <arg name="use_multithread" value="true"/>
        <arg name="use_pointcloud_container" value="$(var use_pointcloud_container)"/>
        <arg name="container_name" value="$(var pointcloud_container_name)"/>
        <arg name="input/pointcloud" value="$(var input/pointcloud)"/>
      </include>
    </group>

    <!-- occupancy grid map module -->
    <group>
      <push-ros-namespace namespace="occupancy_grid_map"/>
      <include file="$(find-pkg-share tier4_perception_launch)/launch/occupancy_grid_map/pointcloud_based_occupancy_grid_map.launch.py">
        <arg name="input/obstacle_pointcloud" value="/perception/obstacle_segmentation/single_frame/pointcloud_raw"/>
        <arg name="input/raw_pointcloud" value="$(var input/pointcloud)"/>
        <arg name="output" value="/perception/occupancy_grid_map/map"/>
        <arg name="use_intra_process" value="true"/>
        <arg name="use_multithread" value="true"/>
        <arg name="use_pointcloud_container" value="$(var use_pointcloud_container)"/>
        <arg name="container_name" value="$(var pointcloud_container_name)"/>
      </include>
    </group>

    <!-- object recognition module -->
    <group unless="$(var use_empty_dynamic_object_publisher)">
      <push-ros-namespace namespace="object_recognition"/>
      <!-- detection module -->
      <group>
        <push-ros-namespace namespace="detection"/>
        <include file="$(find-pkg-share tier4_perception_launch)/launch/object_recognition/detection/digital_twin_detection.launch.xml">
          <arg name="mode" value="$(var mode)"/>
          <arg name="input/pointcloud" value="$(var input/pointcloud)"/>
          <arg name="lidar_detection_model" value="$(var lidar_detection_model)"/>
          <arg name="image_raw0" value="$(var image_raw0)"/>
          <arg name="camera_info0" value="$(var camera_info0)"/>
          <arg name="image_raw1" value="$(var image_raw1)"/>
          <arg name="camera_info1" value="$(var camera_info1)"/>
          <arg name="image_raw2" value="$(var image_raw2)"/>
          <arg name="camera_info2" value="$(var camera_info2)"/>
          <arg name="image_raw3" value="$(var image_raw3)"/>
          <arg name="camera_info3" value="$(var camera_info3)"/>
          <arg name="image_raw4" value="$(var image_raw4)"/>
          <arg name="camera_info4" value="$(var camera_info4)"/>
          <arg name="image_raw5" value="$(var image_raw5)"/>
          <arg name="camera_info5" value="$(var camera_info5)"/>
          <arg name="image_raw6" value="$(var image_raw6)"/>
          <arg name="camera_info6" value="$(var camera_info6)"/>
          <arg name="image_raw7" value="$(var image_raw7)"/>
          <arg name="camera_info7" value="$(var camera_info7)"/>
          <arg name="image_number" value="$(var image_number)"/>
          <arg name="use_pointcloud_map" value="$(var use_pointcloud_map)"/>
          <arg name="use_object_filter" value="$(var use_object_filter)"/>
          <arg name="use_pointcloud_container" value="$(var use_pointcloud_container)"/>
          <arg name="container_name" value="$(var pointcloud_container_name)"/>
        </include>
      </group>
      <!-- tracking module -->
      <group>
        <push-ros-namespace namespace="tracking"/>
        <include file="$(find-pkg-share tier4_perception_launch)/launch/object_recognition/tracking/tracking.launch.xml">
          <arg name="publish_rate" value="30.0"/>
        </include>
      </group>
      <!-- prediction module -->
      <group>
        <push-ros-namespace namespace="prediction"/>
        <include file="$(find-pkg-share tier4_perception_launch)/launch/object_recognition/prediction/prediction.launch.xml">
          <arg name="use_vector_map" value="$(var use_vector_map)"/>
        </include>
      </group>
    </group>

    <group if="$(var use_empty_dynamic_object_publisher)">
      <push-ros-namespace namespace="object_recognition"/>
      <node pkg="dummy_perception_publisher" exec="empty_objects_publisher" name="empty_objects_publisher" output="screen">
        <remap from="~/output/objects" to="/perception/object_recognition/objects"/>
      </node>
    </group>

    <!-- traffic light module -->
    <group if="$(var use_traffic_light_recognition)">
      <push-ros-namespace namespace="traffic_light_recognition"/>
      <include file="$(find-pkg-share tier4_perception_launch)/launch/traffic_light_recognition/traffic_light.launch.xml">
        <arg name="enable_fine_detection" value="$(var traffic_light_recognition/enable_fine_detection)"/>
      </include>
    </group>
  </group>
</launch>
